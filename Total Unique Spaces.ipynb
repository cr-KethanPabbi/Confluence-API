{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save config.py and import the API_KEY and CR_EMAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import API_KEY, CR_EMAIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all unique pages till space 1000. Confluence has a cb limit of 1000 so you must run the next on which starts from space 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaces 1-1000\n",
    "import csv\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "def save_page_details_to_csv(page_details, filename):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Space Name', 'Page Name', 'Created By', 'Last Modified By', 'Last Modified Date', 'Views', 'Web URL'])\n",
    "        for page in page_details:\n",
    "            writer.writerow([\n",
    "                page['space_name'],\n",
    "                page['page_name'],\n",
    "                page['created_by'],\n",
    "                page['last_modified_by'],\n",
    "                page['last_modified_date'],\n",
    "                page['views'],\n",
    "                page['web_url']\n",
    "            ])\n",
    "\n",
    "def get_total_unique_spaces_and_pages_in_confluence():\n",
    "    email = CR_EMAIL\n",
    "    api_token = API_KEY\n",
    "    auth = (email, api_token)\n",
    "    base_url = \"https://cybereason.atlassian.net/wiki/\"\n",
    "    unique_spaces = set()\n",
    "    page_details = []\n",
    "\n",
    "    # Make request to Confluence API to get total number of spaces\n",
    "    limit_spaces = 10000  # Adjust the limit as needed\n",
    "    start_spaces = 0\n",
    "\n",
    "    try:\n",
    "        # Fetch spaces\n",
    "        while True:\n",
    "            spaces_response = requests.get(base_url + f\"rest/api/space?start={start_spaces}&limit={limit_spaces}\", auth=auth)\n",
    "            spaces_data = spaces_response.json()\n",
    "            current_spaces = spaces_data.get('results', [])\n",
    "\n",
    "            # Loop through each space\n",
    "            for space in current_spaces:\n",
    "                space_key = space.get('key')\n",
    "                space_name = space.get('name')\n",
    "                unique_spaces.add(space_key)\n",
    "\n",
    "                # Make request to Confluence API to get total number of pages for current space\n",
    "                pages_response = requests.get(base_url + f\"rest/api/content?spaceKey={space_key}&limit=1000\", auth=auth)\n",
    "                pages_data = pages_response.json().get('results', [])\n",
    "\n",
    "                # Display space name\n",
    "                print(\"Space Name:\", space_name)\n",
    "\n",
    "                # Loop through each page in the current space\n",
    "                for page in pages_data:\n",
    "                    page_id = page.get('id')\n",
    "                    page_name = page.get('title', 'Unknown')\n",
    "                    \n",
    "                    # Fetch detailed information about the page\n",
    "                    page_details_response = requests.get(base_url + f\"rest/api/content/{page_id}\", auth=auth)\n",
    "                    page_details_data = page_details_response.json()\n",
    "                    \n",
    "                    creator = page_details_data.get('history', {}).get('createdBy', {}).get('displayName', 'Unknown')\n",
    "                    \n",
    "                    # Fetching last modified information from version\n",
    "                    last_modified_info = page_details_data.get('version', {}).get('by', {})\n",
    "                    last_modifier = last_modified_info.get('displayName', 'Unknown')\n",
    "                    last_modified_date = page_details_data.get('version', {}).get('friendlyWhen', 'Unknown')\n",
    "                    \n",
    "                    # Fetch views for the page\n",
    "                    views_response = requests.get(base_url + f\"rest/api/analytics/content/{page_id}/views\", auth=auth)\n",
    "                    views_data = views_response.json().get('count', 'Unknown')\n",
    "                    \n",
    "                    web_url = page_details_data.get('_links', {}).get('webui')\n",
    "                    \n",
    "                    # Add page details to the list\n",
    "                    page_details.append({\n",
    "                        'space_name': space_name,\n",
    "                        'page_name': page_name,\n",
    "                        'created_by': creator,\n",
    "                        'last_modified_by': last_modifier,\n",
    "                        'last_modified_date': last_modified_date,\n",
    "                        'views': views_data,\n",
    "                        'web_url': base_url + web_url\n",
    "                    })\n",
    "\n",
    "                # Display total unique pages for current space\n",
    "                print(\"Total Unique Pages in this space:\", len(pages_data))\n",
    "                print()  # Add a blank line for separation\n",
    "\n",
    "            # Check if there are more spaces to fetch\n",
    "            start_spaces += limit_spaces\n",
    "            if 'next' not in spaces_data['_links']:\n",
    "                break\n",
    "\n",
    "        total_unique_spaces = len(unique_spaces)\n",
    "        print(\"\\nTotal unique spaces in Confluence:\", total_unique_spaces)\n",
    "        print(\"Total unique pages in Confluence:\", len(page_details))\n",
    "\n",
    "        # Save page details to CSV\n",
    "        save_page_details_to_csv(page_details, 'confluence_pages.csv')\n",
    "\n",
    "        return {\"total_unique_spaces\": total_unique_spaces, \"total_unique_pages\": len(page_details)}\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nKeyboard interrupt detected. Saving current progress to CSV...\")\n",
    "        save_page_details_to_csv(page_details, 'confluence_pages_interrupted.csv')\n",
    "        print(\"Current progress saved.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        print(\"Saving current progress to CSV...\")\n",
    "        save_page_details_to_csv(page_details, 'confluence_pages_interrupted.csv')\n",
    "        print(\"Current progress saved.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "get_total_unique_spaces_and_pages_in_confluence()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all unique pages from space 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaces 1001 and above\n",
    "import csv\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "def save_page_details_to_csv(page_details, filename):\n",
    "    with open(filename, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for page in page_details:\n",
    "            writer.writerow([\n",
    "                page['space_name'],\n",
    "                page['page_name'],\n",
    "                page['created_by'],\n",
    "                page['last_modified_by'],\n",
    "                page['last_modified_date'],\n",
    "                page['views'],\n",
    "                page['web_url']\n",
    "            ])\n",
    "\n",
    "def get_total_unique_spaces_and_pages_in_confluence(start_index=0):\n",
    "    email = CR_EMAIL\n",
    "    api_token = API_KEY\n",
    "    auth = (email, api_token)\n",
    "    base_url = \"https://cybereason.atlassian.net/wiki/\"\n",
    "    unique_spaces = set()\n",
    "    page_details = []\n",
    "\n",
    "    # Make request to Confluence API to get total number of spaces\n",
    "    limit_spaces = 10000  # Adjust the limit as needed\n",
    "    start_spaces = start_index\n",
    "\n",
    "    try:\n",
    "        # Fetch spaces\n",
    "        while True:\n",
    "            spaces_response = requests.get(base_url + f\"rest/api/space?start={start_spaces}&limit={limit_spaces}\", auth=auth)\n",
    "            spaces_data = spaces_response.json()\n",
    "            current_spaces = spaces_data.get('results', [])\n",
    "\n",
    "            # Loop through each space\n",
    "            for space in current_spaces:\n",
    "                space_key = space.get('key')\n",
    "                space_name = space.get('name')\n",
    "                unique_spaces.add(space_key)\n",
    "\n",
    "                # Make request to Confluence API to get total number of pages for current space\n",
    "                pages_response = requests.get(base_url + f\"rest/api/content?spaceKey={space_key}&limit=1000\", auth=auth)\n",
    "                pages_data = pages_response.json().get('results', [])\n",
    "\n",
    "                # Display space name\n",
    "                print(\"Space Name:\", space_name)\n",
    "\n",
    "                # Loop through each page in the current space\n",
    "                for page in pages_data:\n",
    "                    page_id = page.get('id')\n",
    "                    page_name = page.get('title', 'Unknown')\n",
    "                    \n",
    "                    # Fetch detailed information about the page\n",
    "                    page_details_response = requests.get(base_url + f\"rest/api/content/{page_id}\", auth=auth)\n",
    "                    page_details_data = page_details_response.json()\n",
    "                    \n",
    "                    creator = page_details_data.get('history', {}).get('createdBy', {}).get('displayName', 'Unknown')\n",
    "                    \n",
    "                    # Fetching last modified information from version\n",
    "                    last_modified_info = page_details_data.get('version', {}).get('by', {})\n",
    "                    last_modifier = last_modified_info.get('displayName', 'Unknown')\n",
    "                    last_modified_date = page_details_data.get('version', {}).get('friendlyWhen', 'Unknown')\n",
    "                    \n",
    "                    # Fetch views for the page\n",
    "                    views_response = requests.get(base_url + f\"rest/api/analytics/content/{page_id}/views\", auth=auth)\n",
    "                    views_data = views_response.json().get('count', 'Unknown')\n",
    "                    \n",
    "                    web_url = page_details_data.get('_links', {}).get('webui')\n",
    "                    \n",
    "                    # Add page details to the list\n",
    "                    page_details.append({\n",
    "                        'space_name': space_name,\n",
    "                        'page_name': page_name,\n",
    "                        'created_by': creator,\n",
    "                        'last_modified_by': last_modifier,\n",
    "                        'last_modified_date': last_modified_date,\n",
    "                        'views': views_data,\n",
    "                        'web_url': base_url + web_url\n",
    "                    })\n",
    "\n",
    "                # Display total unique pages for current space\n",
    "                print(\"Total Unique Pages in this space:\", len(pages_data))\n",
    "                print()  # Add a blank line for separation\n",
    "\n",
    "            # Check if there are more spaces to fetch\n",
    "            start_spaces += limit_spaces\n",
    "            if 'next' not in spaces_data['_links']:\n",
    "                break\n",
    "\n",
    "        total_unique_spaces = len(unique_spaces)\n",
    "        print(\"\\nTotal unique spaces in Confluence:\", total_unique_spaces)\n",
    "        print(\"Total unique pages in Confluence:\", len(page_details))\n",
    "\n",
    "        # Save page details to CSV\n",
    "        save_page_details_to_csv(page_details, 'confluence_pages(1000+).csv')\n",
    "\n",
    "        return {\"total_unique_spaces\": total_unique_spaces, \"total_unique_pages\": len(page_details)}\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nKeyboardInterrupt detected.\")\n",
    "        print(\"Saving current progress to CSV...\")\n",
    "        save_page_details_to_csv(page_details, 'confluence_pages_interrupted.csv')\n",
    "        print(\"Current progress saved.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        print(\"Saving current progress to CSV...\")\n",
    "        save_page_details_to_csv(page_details, 'confluence_pages_interrupted.csv')\n",
    "        print(\"Current progress saved.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "get_total_unique_spaces_and_pages_in_confluence(start_index=1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine both csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def combine_csv_files(file1, file2, output_file):\n",
    "    with open(file1, 'r', newline='', encoding='utf-8') as f1, open(file2, 'r', newline='', encoding='utf-8') as f2, open(output_file, 'w', newline='', encoding='utf-8') as out_file:\n",
    "        reader1 = csv.reader(f1)\n",
    "        reader2 = csv.reader(f2)\n",
    "        writer = csv.writer(out_file)\n",
    "\n",
    "        # Write headers from the first file\n",
    "        headers = next(reader1)\n",
    "        writer.writerow(headers)\n",
    "\n",
    "        # Write rows from the first file\n",
    "        for row in reader1:\n",
    "            writer.writerow(row)\n",
    "\n",
    "        # Skip headers in the second file\n",
    "        next(reader2)\n",
    "\n",
    "        # Write rows from the second file\n",
    "        for row in reader2:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Combine CSV files\n",
    "combine_csv_files('confluence_pages.csv', 'confluence_pages(1000+).csv', 'combined_confluence_pages.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
